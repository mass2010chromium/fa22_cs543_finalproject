{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa82d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "/home/yifan/venv/lib/python3.8/site-packages/face_alignment/api.py:145: UserWarning: No faces were detected.\n",
      "  warnings.warn(\"No faces were detected.\")\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import face_alignment\n",
    "import time\n",
    "import cv2\n",
    "import scipy.optimize as opt\n",
    "from calibration.undistort import undistort\n",
    "\n",
    "def draw_marks(image, marks, color=(0, 255, 0), ratio = 1):\n",
    "    \"\"\"\n",
    "    Draw the facial landmarks on an image\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.uint8\n",
    "        Image on which landmarks are to be drawn.\n",
    "    marks : list or numpy array\n",
    "        Facial landmark points\n",
    "    color : tuple, optional\n",
    "        Color to which landmarks are to be drawn with. The default is (0, 255, 0).\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    for mark in marks:\n",
    "        cv.circle(image, (int(mark[0]*ratio), int(mark[1]*ratio)), 2, color, -1, cv.LINE_AA)\n",
    "        \n",
    "\n",
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, device='cuda')\n",
    "\n",
    "# this function compares the differences between two sets of points\n",
    "# each column is a point\n",
    "def err(p1, p2):\n",
    "    # hopefully this is actually correct\n",
    "    return sum(sum((p1 - p2)*(p1 - p2)))\n",
    "\n",
    "\n",
    "\n",
    "# x is an array of 9 elements\n",
    "def to_optimize(x, original_points, target_points):\n",
    "    # reshape it to be a 3x3 transformation matrix\n",
    "    transform = x.reshape((3,3))\n",
    "    temp = transform@original_points\n",
    "    result = np.zeros((2,original_points.shape[1]))\n",
    "    for i in range(original_points.shape[1]):\n",
    "        result[0,i] = temp[0,i]/temp[2,i]\n",
    "        result[1,i] = temp[1,i]/temp[2,i]\n",
    "    return err(result, target_points[:2,:])\n",
    "\n",
    "\n",
    "def crop_image(image):\n",
    "    return image[:,80:-80,:]\n",
    "\n",
    "def capture_initial_video():\n",
    "    original_points = 0\n",
    "    target_points = 0\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    record = False\n",
    "    video_out_1 = cv2.VideoWriter('./video_headset_on2.mp4',cv2.VideoWriter_fourcc(*'XVID'),25,(480,480))\n",
    "    \n",
    "    ## capture jawline with headset on and save the feature pts\n",
    "    while True:\n",
    "        res, frame = cap.read()\n",
    "        if not res:\n",
    "            print('no frame')\n",
    "            continue\n",
    "        cv2.imshow(winname=\"RAW FRAME\", mat=frame)\n",
    "\n",
    "        frame = crop_image(frame)\n",
    "        resized_frame = cv.resize(frame,(256,256))\n",
    "        clean_frame = frame.copy()\n",
    "        preds = fa.get_landmarks(resized_frame)\n",
    "        \n",
    "        if(preds):\n",
    "            headset_features = np.concatenate((preds[0].astype(int)[:17],preds[0].astype(int)[49:61]))\n",
    "            draw_marks(frame,headset_features,color = (255,0,0), ratio = 480/256)\n",
    "\n",
    "        cv2.imshow(winname=\"Face\", mat=cv2.resize(frame,(720,720)))\n",
    "        pressed_key = cv2.waitKey(5) & 0xFF\n",
    "        if pressed_key == ord('q'):\n",
    "            target_points = np.concatenate((preds[0].astype(int)[:17],preds[0].astype(int)[49:61]))\n",
    "            target_points = np.append(target_points, np.ones((target_points.shape[0],1)), axis=1)\n",
    "            target_points = target_points.T\n",
    "            print(\"got target points with shape\", target_points.shape)\n",
    "            break \n",
    "        elif pressed_key == ord('r'):\n",
    "            record = True\n",
    "            \n",
    "        if record:\n",
    "            print(record)\n",
    "            video_out_1.write(clean_frame)\n",
    "            \n",
    "    video_out_1.release()\n",
    "    video_out = cv2.VideoWriter('./video_headset_off2.mp4',cv2.VideoWriter_fourcc(*'XVID'),25,(480,480))\n",
    "    print('now trying to find a good no-headset match')\n",
    "    record = False\n",
    "    \n",
    "    ## align \n",
    "    result_marks = 0\n",
    "    generated_result = False\n",
    "    while True:\n",
    "        res, frame = cap.read()\n",
    "        if not res:\n",
    "            print('no frame')\n",
    "            continue\n",
    "        \n",
    "        frame = crop_image(frame)\n",
    "        resized_frame = cv.resize(frame,(256,256))\n",
    "        \n",
    "        # show the image\n",
    "        preds = fa.get_landmarks(resized_frame)\n",
    "        if(preds):\n",
    "            new_face = preds[0].astype(int)\n",
    "            clean_frame = frame.copy()\n",
    "            draw_marks(frame,new_face,color = (0,0,255), ratio = 480/256)\n",
    "        if generated_result:\n",
    "            print(\"generating result\")\n",
    "            draw_marks(frame,result_marks, color = (0,255,0), ratio = 480/256)\n",
    "            \n",
    "        draw_marks(frame,headset_features,color = (255,0,0), ratio = 480/256)\n",
    "        cv2.imshow(winname=\"Face\", mat=cv2.resize(frame,(720,720)))\n",
    "\n",
    "        pressed_key = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "        if(pressed_key == ord('q')):\n",
    "            print(\"stop recording\")\n",
    "            break\n",
    "        elif(pressed_key == ord('r')):\n",
    "            print('started recording')\n",
    "            record = True\n",
    "            original_points = np.concatenate((preds[0].astype(int)[:17],preds[0].astype(int)[49:61]))\n",
    "            original_points = np.append(original_points, np.ones((original_points.shape[0],1)), axis=1)\n",
    "            original_points = original_points.T\n",
    "            print(original_points.shape)\n",
    "            res = opt.minimize(to_optimize, np.array([1,0,0,0,1,0,0,0,1]), args=(original_points, target_points))\n",
    "            transform = res.x.reshape((3,3))\n",
    "            temp = transform@original_points\n",
    "            result = np.zeros((2,original_points.shape[1]))\n",
    "            for i in range(original_points.shape[1]):\n",
    "                result[0,i] = temp[0,i]/temp[2,i]\n",
    "                result[1,i] = temp[1,i]/temp[2,i]\n",
    "            result_marks = result.T.astype(int)\n",
    "            generated_result = True\n",
    "            print(result_marks)\n",
    "        if(record):\n",
    "            video_out.write(clean_frame)\n",
    "            print(clean_frame.shape)\n",
    "    # When everything done, release the video capture and video write objects\n",
    "    cap.release()\n",
    "    video_out.release()\n",
    "    # Close all windows\n",
    "    cv2.destroyAllWindows()\n",
    "    pickle.dump(clean_frame,open('./starting_picture.p','wb'))\n",
    "    return clean_frame\n",
    "\n",
    "print(\"run\")\n",
    "\n",
    "capture_initial_video()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f2043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
